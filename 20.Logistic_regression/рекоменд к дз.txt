Николай, приветствую!

Спасибо, все супер.

Как вы могли заметить,
 результат может очень 
сильно отличаться в 
зависимости от 
случайного разбиения 
данных на train и test. 
Такое может происходить, 
особенно когда данных не очень много.
 В реальности просто так это оставлять
 нельзя (иначе мы не сможем объективно 
сравнивать разные модели между собой), 
всегда применяются различные механизмы 
кросс-валидации (то есть при обучении
 модели данные разбиваются множеством 
разных способов и считается условно “усредненный” 
лучший результат). Рекомендую ознакомиться вот 
с этим примером, там на этих же данных применяется 
этот механизм в самой своей простой форме:
https://www.statology.org/linear-discriminant-analysis-in-python/

Зачет!