{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "novel-protocol",
   "metadata": {},
   "source": [
    "# Домашнее задание к лекции Улучшение качества модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visible-signature",
   "metadata": {},
   "source": [
    "Взять boston house-prices datase (sklearn.datasets.load_boston). Возьмите 7 любых регрессоров (попробовать разные алгоритмы, поподбирать параметры, вывести итоговое качество)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aboriginal-discussion",
   "metadata": {},
   "source": [
    "Импортируем датасет для работы и методы улучшения качества модели, которые будут работать с гиперпараметрами наших регрессоров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "czech-detroit",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "separated-joseph",
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = load_boston()\n",
    "\n",
    "X = boston.data\n",
    "y = boston.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "catholic-nepal",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 21, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parental-authority",
   "metadata": {},
   "source": [
    "## RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bearing-bailey",
   "metadata": {},
   "source": [
    "Импортируем все регрессоры, которые интересно посмотреть в данной задаче."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "level-sharing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge, BayesianRidge, TweedieRegressor, SGDRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "operational-geology",
   "metadata": {},
   "source": [
    "Ниже метод для игнорирования предупреждений в процессе работы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "virgin-router",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "potential-furniture",
   "metadata": {},
   "source": [
    "Поместим все регрессоры с некоторыми гиперпараметрами и некоторыми значениями в список models. Далее будем пробегаться по нему и прогонять через оптимизатор, сначала через RandomizedSearchCV, а затем через GridSearchCV. Далее выводить метрика качества."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "generous-david",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    {'name':'R',\"model\": Ridge(), 'params':{'solver':['svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga']}},\n",
    "    {'name':'BR',\"model\": BayesianRidge(), 'params':{'alpha_1':[1e-6, 1e-7, 1e-5], 'lambda_1':[1e-6, 1e-7, 1e-5]}},\n",
    "    {'name':'TwR',\"model\": TweedieRegressor(), 'params':{'power':[0, 1, 2, 3], 'alpha':[0, 0.25, 0.5, 0.75, 1]}},\n",
    "    {'name':'SGD',\"model\": SGDRegressor(), 'params':{'penalty':['l2', 'l1', 'elasticnet'], 'learning_rate':['constant', 'optimal', 'invscaling', 'adaptive'], 'power_t':[0.1, 0.2, 0.5, 0.7]}},\n",
    "    {'name':'RFor',\"model\": RandomForestRegressor(), 'params':{'n_estimators': [50, 75, 100, 125], 'max_features': ['auto', 'sqrt', 'log2']}},\n",
    "    {'name':'DTr',\"model\": DecisionTreeRegressor(), 'params':{'criterion':['mse', 'mae', 'poisson', 'friedman_mse'], 'splitter': ['best', 'random']}},\n",
    "    {'name':'SVR',\"model\": SVR(), 'params':{'degree':[1, 2, 3, 4]}},\n",
    "    {'name':'GBooR',\"model\": GradientBoostingRegressor(), 'params':{'loss':['ls', 'lad', 'huber', 'quantile'], 'max_depth':[3,5,7,9,11], 'n_estimators':[75, 100, 125], 'criterion': ['friedman_mse', 'mse', 'mae']}},\n",
    "    {'name':'KR',\"model\": KernelRidge(), 'params':{'degree':[1, 2, 3, 4, 5]}},\n",
    "    {'name':'KNeigh',\"model\": KNeighborsRegressor(), 'params':{'n_neighbors':[3, 4, 5, 7, 9], 'weights':['uniform', 'distance'], 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']}}\n",
    "]\n",
    "\n",
    "res = []\n",
    "for v in models:\n",
    "    res.append((v['name'], RandomizedSearchCV(v['model'], v['params'], cv=10).fit(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "indirect-norfolk",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R 0.7081684796000693 {'solver': 'svd'}\n",
      "BR 0.6976310910353944 {'lambda_1': 1e-07, 'alpha_1': 1e-05}\n",
      "TwR 0.7592429678495294 {'power': 1, 'alpha': 0.5}\n",
      "SGD -5.547116447238407e+21 {'power_t': 0.7, 'penalty': 'l1', 'learning_rate': 'invscaling'}\n",
      "RFor 0.856833610794857 {'n_estimators': 100, 'max_features': 'log2'}\n",
      "DTr 0.7065813251781716 {'splitter': 'best', 'criterion': 'mae'}\n",
      "SVR 0.20234179199604027 {'degree': 1}\n",
      "GBooR 0.8395594278509391 {'n_estimators': 125, 'max_depth': 9, 'loss': 'lad', 'criterion': 'friedman_mse'}\n",
      "KR 0.6711343480075428 {'degree': 1}\n",
      "KNeigh 0.5470430341221104 {'weights': 'distance', 'n_neighbors': 9, 'algorithm': 'ball_tree'}\n"
     ]
    }
   ],
   "source": [
    "for r in res:\n",
    "    print(r[0], r[1].best_score_, r[1].best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "destroyed-johns",
   "metadata": {},
   "source": [
    "При оптимизаторе RandomizedSearchCV лучше всего справился регрессор RandomForestRegressor - 0.857, затем GradientBoostingRegressor - 0.840 и т.д."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "relevant-maldives",
   "metadata": {},
   "source": [
    "## GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "circular-chain",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_grid = []\n",
    "for w in models:\n",
    "    res_grid.append((w['name'], GridSearchCV(w['model'], w['params'], cv=10).fit(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "looking-glory",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R 0.7081684796000693 {'solver': 'svd'}\n",
      "BR 0.6976310910353944 {'alpha_1': 1e-05, 'lambda_1': 1e-07}\n",
      "TwR 0.7663448806170917 {'alpha': 0, 'power': 1}\n",
      "SGD -1.1101914595001407e+21 {'learning_rate': 'invscaling', 'penalty': 'l2', 'power_t': 0.7}\n",
      "RFor 0.854803887374295 {'max_features': 'sqrt', 'n_estimators': 50}\n",
      "DTr 0.7416904712660894 {'criterion': 'mae', 'splitter': 'random'}\n",
      "SVR 0.20234179199604027 {'degree': 1}\n",
      "GBooR 0.8583827723593952 {'criterion': 'mse', 'loss': 'huber', 'max_depth': 3, 'n_estimators': 100}\n",
      "KR 0.6711343480075428 {'degree': 1}\n",
      "KNeigh 0.5470430341221104 {'algorithm': 'auto', 'n_neighbors': 9, 'weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "for r in res_grid:\n",
    "    print(r[0], r[1].best_score_, r[1].best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "identical-behavior",
   "metadata": {},
   "source": [
    "При оптимизаторе GridSearchCV лучше всего справился регрессор GradientBoostingRegressor - 0.858, затем RandomForestRegressor - 0.855 и т.д. Надо отметить, что время потраченное на оптимизацию значительно выше, чем в оптимизаторе выше, это и объясняется его концепцией работы.\n",
    "\n",
    "Если сравнивать качества между этими двумя оптимизаторами, то GridSearchCV немного выше на тысячные доли, если важно достичь результатов тысячных долей и данных не слишком много, и есть мощности для работы, то GridSearchCV простой и действенный выбор оптимизации гиперпараметров, а если важнее время на больших объемах данных, то тогда RandomizedSearchCV."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
